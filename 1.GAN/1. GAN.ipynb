{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Data Set!\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Finished Downloading!\n",
      "starting training for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Pretraining. Generating images for label 0\n",
      "Iteration 4000. G_loss 2.8428444862365723. D_loss 0.5134157538414001\n",
      "Iteration 4100. G_loss 2.9339513778686523. D_loss 0.5563892126083374\n",
      "Iteration 4200. G_loss 1.966720461845398. D_loss 1.7525829076766968\n",
      "Iteration 4300. G_loss 4.249795436859131. D_loss 0.27473318576812744\n",
      "Iteration 4400. G_loss 2.9513537883758545. D_loss 1.1156485080718994\n",
      "Iteration 4500. G_loss 2.233975648880005. D_loss 0.5515741109848022\n",
      "Iteration 4600. G_loss 3.739232063293457. D_loss 0.5353230237960815\n",
      "Iteration 4700. G_loss 2.2618374824523926. D_loss 0.9601085186004639\n",
      "Iteration 4800. G_loss 2.7380096912384033. D_loss 1.1318926811218262\n",
      "Iteration 4900. G_loss 0.9361871480941772. D_loss 1.0769093036651611\n",
      "Iteration 5000. G_loss 1.4824261665344238. D_loss 0.9488405585289001\n",
      "Iteration 5100. G_loss 2.5393171310424805. D_loss 0.9141188263893127\n",
      "Iteration 5200. G_loss 2.6399848461151123. D_loss 0.8871872425079346\n",
      "Iteration 5300. G_loss 1.0815409421920776. D_loss 1.093346357345581\n",
      "Iteration 5400. G_loss 3.352835178375244. D_loss 1.103340744972229\n",
      "Iteration 5500. G_loss 1.9139759540557861. D_loss 0.8217626810073853\n",
      "Iteration 5600. G_loss 0.6860840320587158. D_loss 1.1477158069610596\n",
      "Iteration 5700. G_loss 1.544830322265625. D_loss 0.9106687307357788\n",
      "Iteration 5800. G_loss 2.7458112239837646. D_loss 1.0096936225891113\n",
      "Iteration 5900. G_loss 1.4904481172561646. D_loss 1.0441803932189941\n",
      "Iteration 6000. G_loss 1.7436009645462036. D_loss 1.1126407384872437\n",
      "Iteration 6100. G_loss 1.2026103734970093. D_loss 1.1800652742385864\n",
      "Iteration 6200. G_loss 1.8072429895401. D_loss 0.7424353957176208\n",
      "Iteration 6300. G_loss 1.1449557542800903. D_loss 1.2325565814971924\n",
      "Iteration 6400. G_loss 1.4029583930969238. D_loss 0.778035581111908\n",
      "Iteration 6500. G_loss 1.5167181491851807. D_loss 1.3028624057769775\n",
      "Iteration 6600. G_loss 2.107348680496216. D_loss 0.83738112449646\n",
      "Iteration 6700. G_loss 1.8534356355667114. D_loss 0.7395384311676025\n",
      "Iteration 6800. G_loss 1.1530929803848267. D_loss 0.9521327614784241\n",
      "Iteration 6900. G_loss 1.6668517589569092. D_loss 1.1171009540557861\n",
      "starting training for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Pretraining. Generating images for label 1\n",
      "Iteration 4000. G_loss 3.224416494369507. D_loss 0.10004737228155136\n",
      "Iteration 4100. G_loss 3.2100205421447754. D_loss 0.1251724660396576\n",
      "Iteration 4200. G_loss 3.3176887035369873. D_loss 0.8403459191322327\n",
      "Iteration 4300. G_loss 4.011810779571533. D_loss 0.14801350235939026\n",
      "Iteration 4400. G_loss 2.1164588928222656. D_loss 1.2148315906524658\n",
      "Iteration 4500. G_loss 1.930208444595337. D_loss 0.6691707968711853\n",
      "Iteration 4600. G_loss 1.8008860349655151. D_loss 0.33589157462120056\n",
      "Iteration 4700. G_loss 3.2745859622955322. D_loss 0.4220845699310303\n",
      "Iteration 4800. G_loss 1.6960967779159546. D_loss 0.5118044018745422\n",
      "Iteration 4900. G_loss 1.5774099826812744. D_loss 0.9333683848381042\n",
      "Iteration 5000. G_loss 2.416332960128784. D_loss 0.8386393785476685\n",
      "Iteration 5100. G_loss 2.698096990585327. D_loss 0.5430269837379456\n",
      "Iteration 5200. G_loss 0.8584650158882141. D_loss 0.8554224967956543\n",
      "Iteration 5300. G_loss 1.579665184020996. D_loss 1.011765956878662\n",
      "Iteration 5400. G_loss 1.1169472932815552. D_loss 0.861204981803894\n",
      "Iteration 5500. G_loss 2.2182700634002686. D_loss 0.670468807220459\n",
      "Iteration 5600. G_loss 0.5741847157478333. D_loss 1.249358892440796\n",
      "Iteration 5700. G_loss 1.4017665386199951. D_loss 1.2103338241577148\n",
      "Iteration 5800. G_loss 1.0176136493682861. D_loss 1.3364052772521973\n",
      "Iteration 5900. G_loss 2.06844425201416. D_loss 1.1286439895629883\n",
      "Iteration 6000. G_loss 1.9681625366210938. D_loss 0.9548272490501404\n",
      "Iteration 6100. G_loss 1.2303520441055298. D_loss 1.886098027229309\n",
      "Iteration 6200. G_loss 1.4578012228012085. D_loss 0.8316532373428345\n",
      "Iteration 6300. G_loss 2.0468716621398926. D_loss 0.8315908312797546\n",
      "Iteration 6400. G_loss 0.8482731580734253. D_loss 2.526993989944458\n",
      "Iteration 6500. G_loss 2.8789215087890625. D_loss 0.5796388387680054\n",
      "Iteration 6600. G_loss 1.8735604286193848. D_loss 1.1457703113555908\n",
      "Iteration 6700. G_loss 0.7853684425354004. D_loss 0.9591104388237\n",
      "Iteration 6800. G_loss 1.9760754108428955. D_loss 0.6424788236618042\n",
      "Iteration 6900. G_loss 1.6853665113449097. D_loss 1.0751323699951172\n",
      "starting training for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Pretraining. Generating images for label 2\n",
      "Iteration 4000. G_loss 3.6570067405700684. D_loss 0.0979263186454773\n",
      "Iteration 4100. G_loss 5.130584716796875. D_loss 0.025740116834640503\n",
      "Iteration 4200. G_loss 4.990821361541748. D_loss 0.03569513559341431\n",
      "Iteration 4300. G_loss 6.718930721282959. D_loss 0.06733132898807526\n",
      "Iteration 4400. G_loss 5.353214740753174. D_loss 0.05502624064683914\n",
      "Iteration 4500. G_loss 5.104928970336914. D_loss 0.07072357833385468\n",
      "Iteration 4600. G_loss 6.57752799987793. D_loss 0.294053316116333\n",
      "Iteration 4700. G_loss 4.237409591674805. D_loss 0.054474830627441406\n",
      "Iteration 4800. G_loss 3.509911298751831. D_loss 0.3556109666824341\n",
      "Iteration 4900. G_loss 4.974987030029297. D_loss 0.3030577003955841\n",
      "Iteration 5000. G_loss 2.064340114593506. D_loss 0.1897183656692505\n",
      "Iteration 5100. G_loss 2.8432679176330566. D_loss 0.38393932580947876\n",
      "Iteration 5200. G_loss 4.653966903686523. D_loss 0.2027542144060135\n",
      "Iteration 5300. G_loss 6.604550838470459. D_loss 0.28732869029045105\n",
      "Iteration 5400. G_loss 3.449376106262207. D_loss 0.23681890964508057\n",
      "Iteration 5500. G_loss 2.9734649658203125. D_loss 0.1569478064775467\n",
      "Iteration 5600. G_loss 2.023272752761841. D_loss 0.21946944296360016\n",
      "Iteration 5700. G_loss 5.320364475250244. D_loss 0.256155788898468\n",
      "Iteration 5800. G_loss 2.105820655822754. D_loss 0.3893153667449951\n",
      "Iteration 5900. G_loss 2.3561768531799316. D_loss 0.6472538113594055\n",
      "Iteration 6000. G_loss 3.1509387493133545. D_loss 0.5911942720413208\n",
      "Iteration 6100. G_loss 2.916506290435791. D_loss 0.683593213558197\n",
      "Iteration 6200. G_loss 4.5679755210876465. D_loss 0.3730614483356476\n",
      "Iteration 6300. G_loss 2.598586082458496. D_loss 0.7026504278182983\n",
      "Iteration 6400. G_loss 2.8642423152923584. D_loss 0.46631568670272827\n",
      "Iteration 6500. G_loss 2.0883188247680664. D_loss 0.7404135465621948\n",
      "Iteration 6600. G_loss 2.2533857822418213. D_loss 0.9219157695770264\n",
      "Iteration 6700. G_loss 3.448897123336792. D_loss 0.3252648711204529\n",
      "Iteration 6800. G_loss 2.583132266998291. D_loss 0.5665268898010254\n",
      "Iteration 6900. G_loss 3.4663689136505127. D_loss 0.6488634347915649\n",
      "starting training for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n",
      "Pretraining. Generating images for label 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4000. G_loss 8.550925254821777. D_loss 0.0013461478520184755\n",
      "Iteration 4100. G_loss 7.480990409851074. D_loss 0.0010601007379591465\n",
      "Iteration 4200. G_loss 8.220484733581543. D_loss 0.007274779956787825\n",
      "Iteration 4300. G_loss 6.321098804473877. D_loss 0.009988592937588692\n",
      "Iteration 4400. G_loss 4.996644973754883. D_loss 0.011974642053246498\n",
      "Iteration 4500. G_loss 7.640294075012207. D_loss 0.0017592397052794695\n",
      "Iteration 4600. G_loss 7.554096698760986. D_loss 0.0005834251060150564\n",
      "Iteration 4700. G_loss 5.471369743347168. D_loss 0.008867545984685421\n",
      "Iteration 4800. G_loss 4.773042678833008. D_loss 0.02011105790734291\n",
      "Iteration 4900. G_loss 6.1148576736450195. D_loss 0.0035893016029149294\n",
      "Iteration 5000. G_loss 8.276751518249512. D_loss 0.0005651027895510197\n",
      "Iteration 5100. G_loss 6.368892669677734. D_loss 0.0018152556149289012\n",
      "Iteration 5200. G_loss 6.6360087394714355. D_loss 0.011648780666291714\n",
      "Iteration 5300. G_loss 8.50613784790039. D_loss 0.0016389407683163881\n",
      "Iteration 5400. G_loss 5.943108558654785. D_loss 0.0873231440782547\n",
      "Iteration 5500. G_loss 7.146930694580078. D_loss 0.0036141532473266125\n",
      "Iteration 5600. G_loss 10.821423530578613. D_loss 0.0018249211134389043\n",
      "Iteration 5700. G_loss 13.342585563659668. D_loss 0.010424920357763767\n",
      "Iteration 5800. G_loss 8.608104705810547. D_loss 0.007873664610087872\n",
      "Iteration 5900. G_loss 5.737435340881348. D_loss 0.01828727498650551\n",
      "Iteration 6000. G_loss 7.617183685302734. D_loss 0.05043443292379379\n",
      "Iteration 6100. G_loss 6.505028247833252. D_loss 0.0029812895227223635\n",
      "Iteration 6200. G_loss 6.44209098815918. D_loss 0.002855556784197688\n",
      "Iteration 6300. G_loss 9.973657608032227. D_loss 0.00013138510985299945\n",
      "Iteration 6400. G_loss 6.613597869873047. D_loss 0.006346115842461586\n",
      "Iteration 6500. G_loss 7.778644561767578. D_loss 0.001450287294574082\n",
      "Iteration 6600. G_loss 7.2326154708862305. D_loss 0.0052525051869452\n",
      "Iteration 6700. G_loss 5.604359149932861. D_loss 0.1016044169664383\n",
      "Iteration 6800. G_loss 3.9886059761047363. D_loss 0.018057337030768394\n",
      "Iteration 6900. G_loss 5.793628692626953. D_loss 0.04544900357723236\n",
      "starting training for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Pretraining. Generating images for label 4\n",
      "Iteration 4000. G_loss 6.005712509155273. D_loss 0.007143533788621426\n",
      "Iteration 4100. G_loss 4.568270206451416. D_loss 0.008980711922049522\n",
      "Iteration 4200. G_loss 7.36802864074707. D_loss 0.0010010856203734875\n",
      "Iteration 4300. G_loss 7.286893844604492. D_loss 0.003367252182215452\n",
      "Iteration 4400. G_loss 7.310551166534424. D_loss 0.005859579890966415\n",
      "Iteration 4500. G_loss 5.628538608551025. D_loss 0.0035188947804272175\n",
      "Iteration 4600. G_loss 13.701735496520996. D_loss 0.060193367302417755\n",
      "Iteration 4700. G_loss 13.110235214233398. D_loss 0.004039183724671602\n",
      "Iteration 4800. G_loss 9.608327865600586. D_loss 0.0020169992931187153\n",
      "Iteration 4900. G_loss 6.356141567230225. D_loss 0.07280943542718887\n",
      "Iteration 5000. G_loss 7.6576080322265625. D_loss 0.0012650277931243181\n",
      "Iteration 5100. G_loss 5.431771278381348. D_loss 0.01638653129339218\n",
      "Iteration 5200. G_loss 8.553805351257324. D_loss 0.012078731320798397\n",
      "Iteration 5300. G_loss 6.273016452789307. D_loss 0.01428437139838934\n",
      "Iteration 5400. G_loss 4.995852470397949. D_loss 0.009684678167104721\n",
      "Iteration 5500. G_loss 6.614424228668213. D_loss 0.008016535080969334\n",
      "Iteration 5600. G_loss 5.486898422241211. D_loss 0.014981218613684177\n",
      "Iteration 5700. G_loss 7.346185207366943. D_loss 0.08656541258096695\n",
      "Iteration 5800. G_loss 4.891989707946777. D_loss 0.06374121457338333\n",
      "Iteration 5900. G_loss 5.289227485656738. D_loss 0.11035358160734177\n",
      "Iteration 6000. G_loss 6.568511962890625. D_loss 0.04033183306455612\n",
      "Iteration 6100. G_loss 4.018488883972168. D_loss 0.060815609991550446\n",
      "Iteration 6200. G_loss 6.578831672668457. D_loss 0.04702049493789673\n",
      "Iteration 6300. G_loss 5.501628875732422. D_loss 0.10475439578294754\n",
      "Iteration 6400. G_loss 8.362832069396973. D_loss 0.028987707570195198\n",
      "Iteration 6500. G_loss 8.270308494567871. D_loss 0.03460587561130524\n",
      "Iteration 6600. G_loss 6.711834907531738. D_loss 0.0324459969997406\n",
      "Iteration 6700. G_loss 9.381867408752441. D_loss 0.0017566991737112403\n",
      "Iteration 6800. G_loss 6.5659894943237305. D_loss 0.1185775101184845\n",
      "Iteration 6900. G_loss 7.320427894592285. D_loss 0.026350580155849457\n",
      "starting training for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Pretraining. Generating images for label 5\n",
      "Iteration 4000. G_loss 4.448231220245361. D_loss 0.014977018348872662\n",
      "Iteration 4100. G_loss 5.366471767425537. D_loss 0.008416246622800827\n",
      "Iteration 4200. G_loss 3.58549427986145. D_loss 0.028405562043190002\n",
      "Iteration 4300. G_loss 4.1577630043029785. D_loss 0.030869241803884506\n",
      "Iteration 4400. G_loss 6.591578483581543. D_loss 0.04254908487200737\n",
      "Iteration 4500. G_loss 7.79168701171875. D_loss 0.10076096653938293\n",
      "Iteration 4600. G_loss 7.22557258605957. D_loss 0.020647462457418442\n",
      "Iteration 4700. G_loss 7.2771100997924805. D_loss 0.006559719331562519\n",
      "Iteration 4800. G_loss 6.787881851196289. D_loss 0.05709102749824524\n",
      "Iteration 4900. G_loss 5.117146968841553. D_loss 0.0313359834253788\n",
      "Iteration 5000. G_loss 6.27099609375. D_loss 0.07196603715419769\n",
      "Iteration 5100. G_loss 8.816962242126465. D_loss 0.058811359107494354\n",
      "Iteration 5200. G_loss 6.571677207946777. D_loss 0.07207769900560379\n",
      "Iteration 5300. G_loss 6.340438365936279. D_loss 0.019141102209687233\n",
      "Iteration 5400. G_loss 5.716807842254639. D_loss 0.015285034663975239\n",
      "Iteration 5500. G_loss 7.223587512969971. D_loss 0.2427399605512619\n",
      "Iteration 5600. G_loss 2.0465919971466064. D_loss 0.0066551342606544495\n",
      "Iteration 5700. G_loss 5.745651721954346. D_loss 0.024993527680635452\n",
      "Iteration 5800. G_loss 7.957475185394287. D_loss 0.07660209387540817\n",
      "Iteration 5900. G_loss 8.137177467346191. D_loss 0.34622547030448914\n",
      "Iteration 6000. G_loss 8.924941062927246. D_loss 0.19346752762794495\n",
      "Iteration 6100. G_loss 5.429791450500488. D_loss 0.21065813302993774\n",
      "Iteration 6200. G_loss 4.312288761138916. D_loss 0.21283261477947235\n",
      "Iteration 6300. G_loss 4.539400100708008. D_loss 0.2763271629810333\n",
      "Iteration 6400. G_loss 4.353200912475586. D_loss 0.3230920732021332\n",
      "Iteration 6500. G_loss 3.0083518028259277. D_loss 0.7048466205596924\n",
      "Iteration 6600. G_loss 5.332220077514648. D_loss 0.42088937759399414\n",
      "Iteration 6700. G_loss 5.442901611328125. D_loss 0.3775215744972229\n",
      "Iteration 6800. G_loss 5.6813178062438965. D_loss 0.39415445923805237\n",
      "Iteration 6900. G_loss 6.891739368438721. D_loss 0.48519405722618103\n",
      "starting training for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Pretraining. Generating images for label 6\n",
      "Iteration 4000. G_loss 5.97517204284668. D_loss 0.033215079456567764\n",
      "Iteration 4100. G_loss 4.34843635559082. D_loss 0.018910350278019905\n",
      "Iteration 4200. G_loss 4.302080154418945. D_loss 0.14151637256145477\n",
      "Iteration 4300. G_loss 8.525396347045898. D_loss 0.027740314602851868\n",
      "Iteration 4400. G_loss 3.630147695541382. D_loss 0.1310686618089676\n",
      "Iteration 4500. G_loss 1.506864309310913. D_loss 1.1527559757232666\n",
      "Iteration 4600. G_loss 2.703598737716675. D_loss 0.3892412781715393\n",
      "Iteration 4700. G_loss 2.6571085453033447. D_loss 0.7236692309379578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4800. G_loss 5.633768081665039. D_loss 0.1488787829875946\n",
      "Iteration 4900. G_loss 3.8487398624420166. D_loss 0.10808546841144562\n",
      "Iteration 5000. G_loss 2.1483707427978516. D_loss 0.4477398693561554\n",
      "Iteration 5100. G_loss 3.346001386642456. D_loss 0.4214607775211334\n",
      "Iteration 5200. G_loss 2.8202712535858154. D_loss 0.6246194243431091\n",
      "Iteration 5300. G_loss 1.6003973484039307. D_loss 0.9692613482475281\n",
      "Iteration 5400. G_loss 1.6731514930725098. D_loss 0.45794323086738586\n",
      "Iteration 5500. G_loss 2.441239356994629. D_loss 0.8312642574310303\n",
      "Iteration 5600. G_loss 1.9795794486999512. D_loss 1.0345816612243652\n",
      "Iteration 5700. G_loss 2.943171977996826. D_loss 0.29302945733070374\n",
      "Iteration 5800. G_loss 1.6442360877990723. D_loss 0.6971836090087891\n",
      "Iteration 5900. G_loss 3.0674219131469727. D_loss 0.6405898332595825\n",
      "Iteration 6000. G_loss 3.09423828125. D_loss 0.9314014911651611\n",
      "Iteration 6100. G_loss 2.515554904937744. D_loss 0.6401236653327942\n",
      "Iteration 6200. G_loss 1.6269820928573608. D_loss 0.7987174391746521\n",
      "Iteration 6300. G_loss 2.0415561199188232. D_loss 0.8970905542373657\n",
      "Iteration 6400. G_loss 1.2846201658248901. D_loss 1.0025140047073364\n",
      "Iteration 6500. G_loss 1.7267804145812988. D_loss 0.8369877934455872\n",
      "Iteration 6600. G_loss 2.73002290725708. D_loss 0.9078265428543091\n",
      "Iteration 6700. G_loss 2.6976330280303955. D_loss 0.6376127004623413\n",
      "Iteration 6800. G_loss 2.7563390731811523. D_loss 0.4651561379432678\n",
      "Iteration 6900. G_loss 1.3062611818313599. D_loss 1.148868441581726\n",
      "starting training for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Pretraining. Generating images for label 7\n",
      "Iteration 4000. G_loss 8.315207481384277. D_loss 0.0020041242241859436\n",
      "Iteration 4100. G_loss 7.399728775024414. D_loss 0.005398561712354422\n",
      "Iteration 4200. G_loss 6.651679515838623. D_loss 0.005852659232914448\n",
      "Iteration 4300. G_loss 6.559675216674805. D_loss 0.021268827840685844\n",
      "Iteration 4400. G_loss 8.13988971710205. D_loss 0.009360220283269882\n",
      "Iteration 4500. G_loss 8.689248085021973. D_loss 0.001396906329318881\n",
      "Iteration 4600. G_loss 6.9037675857543945. D_loss 0.0035678220447152853\n",
      "Iteration 4700. G_loss 5.151856899261475. D_loss 0.0047015417367219925\n",
      "Iteration 4800. G_loss 7.58927059173584. D_loss 0.002684791339561343\n",
      "Iteration 4900. G_loss 5.493171215057373. D_loss 0.034926313906908035\n",
      "Iteration 5000. G_loss 2.657008409500122. D_loss 0.03926053270697594\n",
      "Iteration 5100. G_loss 5.223135948181152. D_loss 0.01797882281243801\n",
      "Iteration 5200. G_loss 7.090740203857422. D_loss 0.012860432267189026\n",
      "Iteration 5300. G_loss 4.118187427520752. D_loss 0.012917152605950832\n",
      "Iteration 5400. G_loss 3.3011105060577393. D_loss 0.13421927392482758\n",
      "Iteration 5500. G_loss 5.446530818939209. D_loss 0.04235121235251427\n",
      "Iteration 5600. G_loss 4.481715202331543. D_loss 0.0904499813914299\n",
      "Iteration 5700. G_loss 6.143031120300293. D_loss 0.04873687028884888\n",
      "Iteration 5800. G_loss 3.36384654045105. D_loss 0.13270537555217743\n",
      "Iteration 5900. G_loss 6.26154899597168. D_loss 0.873742938041687\n",
      "Iteration 6000. G_loss 4.810944080352783. D_loss 0.3051685094833374\n",
      "Iteration 6100. G_loss 5.58084774017334. D_loss 0.11136534065008163\n",
      "Iteration 6200. G_loss 3.1590442657470703. D_loss 0.2062273621559143\n",
      "Iteration 6300. G_loss 2.9512929916381836. D_loss 1.0000444650650024\n",
      "Iteration 6400. G_loss 3.3423659801483154. D_loss 0.15216512978076935\n",
      "Iteration 6500. G_loss 4.132776737213135. D_loss 0.6195905208587646\n",
      "Iteration 6600. G_loss 2.5858969688415527. D_loss 0.48041242361068726\n",
      "Iteration 6700. G_loss 3.6083734035491943. D_loss 0.5153369903564453\n",
      "Iteration 6800. G_loss 4.086342811584473. D_loss 0.5352442264556885\n",
      "Iteration 6900. G_loss 0.9867125153541565. D_loss 0.6577866077423096\n",
      "starting training for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Pretraining. Generating images for label 8\n",
      "Iteration 4000. G_loss 6.540093898773193. D_loss 0.0026828423142433167\n",
      "Iteration 4100. G_loss 4.971419811248779. D_loss 0.012805009260773659\n",
      "Iteration 4200. G_loss 5.336495876312256. D_loss 0.03567900508642197\n",
      "Iteration 4300. G_loss 5.882193088531494. D_loss 0.005156354513019323\n",
      "Iteration 4400. G_loss 9.647424697875977. D_loss 0.000568923307582736\n",
      "Iteration 4500. G_loss 7.021344184875488. D_loss 0.014820665121078491\n",
      "Iteration 4600. G_loss 6.88514518737793. D_loss 0.199334517121315\n",
      "Iteration 4700. G_loss 6.9656524658203125. D_loss 0.014486976899206638\n",
      "Iteration 4800. G_loss 6.255364894866943. D_loss 0.029715947806835175\n",
      "Iteration 4900. G_loss 6.373818397521973. D_loss 0.006835061125457287\n",
      "Iteration 5000. G_loss 5.482172012329102. D_loss 0.11105483770370483\n",
      "Iteration 5100. G_loss 8.229040145874023. D_loss 0.13049115240573883\n",
      "Iteration 5200. G_loss 4.111539363861084. D_loss 0.07719157636165619\n",
      "Iteration 5300. G_loss 6.652130126953125. D_loss 0.00888599269092083\n",
      "Iteration 5400. G_loss 4.904239654541016. D_loss 0.0651964619755745\n",
      "Iteration 5500. G_loss 7.271256923675537. D_loss 0.11693111062049866\n",
      "Iteration 5600. G_loss 4.0843939781188965. D_loss 0.09015189856290817\n",
      "Iteration 5700. G_loss 9.060772895812988. D_loss 0.07017665356397629\n",
      "Iteration 5800. G_loss 3.161398410797119. D_loss 0.23720002174377441\n",
      "Iteration 5900. G_loss 5.33561897277832. D_loss 0.1218324601650238\n",
      "Iteration 6000. G_loss 3.2688252925872803. D_loss 0.30711328983306885\n",
      "Iteration 6100. G_loss 4.2362871170043945. D_loss 0.7781945466995239\n",
      "Iteration 6200. G_loss 5.265912055969238. D_loss 0.16344694793224335\n",
      "Iteration 6300. G_loss 3.406669855117798. D_loss 0.20830921828746796\n",
      "Iteration 6400. G_loss 4.928181171417236. D_loss 0.41392016410827637\n",
      "Iteration 6500. G_loss 3.747957706451416. D_loss 0.28036531805992126\n",
      "Iteration 6600. G_loss 3.922325372695923. D_loss 0.3124191462993622\n",
      "Iteration 6700. G_loss 4.312013149261475. D_loss 0.1962583065032959\n",
      "Iteration 6800. G_loss 5.966834545135498. D_loss 0.6700713038444519\n",
      "Iteration 6900. G_loss 4.4984354972839355. D_loss 0.4907952547073364\n",
      "starting training for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Pretraining. Generating images for label 9\n",
      "Iteration 4000. G_loss 8.356200218200684. D_loss 0.000692379311658442\n",
      "Iteration 4100. G_loss 8.341741561889648. D_loss 0.001227099448442459\n",
      "Iteration 4200. G_loss 8.654996871948242. D_loss 0.002260990208014846\n",
      "Iteration 4300. G_loss 7.175384998321533. D_loss 0.005400449503213167\n",
      "Iteration 4400. G_loss 7.705567836761475. D_loss 0.0018903037998825312\n",
      "Iteration 4500. G_loss 14.40304946899414. D_loss 1.563100886414759e-05\n",
      "Iteration 4600. G_loss 10.03078842163086. D_loss 0.0001427095412509516\n",
      "Iteration 4700. G_loss 14.13859748840332. D_loss 0.010560894384980202\n",
      "Iteration 4800. G_loss 5.849876880645752. D_loss 0.7777780294418335\n",
      "Iteration 4900. G_loss 14.033034324645996. D_loss 0.057784680277109146\n",
      "Iteration 5000. G_loss 9.342281341552734. D_loss 0.0020138039253652096\n",
      "Iteration 5100. G_loss 8.885879516601562. D_loss 0.009190141223371029\n",
      "Iteration 5200. G_loss 7.868452072143555. D_loss 0.01734372042119503\n",
      "Iteration 5300. G_loss 6.5005412101745605. D_loss 0.10608218610286713\n",
      "Iteration 5400. G_loss 6.681243419647217. D_loss 0.0073304930701851845\n",
      "Iteration 5500. G_loss 6.544985294342041. D_loss 0.002046694280579686\n",
      "Iteration 5600. G_loss 9.518348693847656. D_loss 0.00022586347768083215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5700. G_loss 7.766274452209473. D_loss 0.0015256399055942893\n",
      "Iteration 5800. G_loss 7.450286865234375. D_loss 0.10879313200712204\n",
      "Iteration 5900. G_loss 6.400068759918213. D_loss 0.006541799753904343\n",
      "Iteration 6000. G_loss 6.356888294219971. D_loss 0.004077949561178684\n",
      "Iteration 6100. G_loss 5.884937763214111. D_loss 0.0015936307609081268\n",
      "Iteration 6200. G_loss 15.45498275756836. D_loss 0.0001289268839173019\n",
      "Iteration 6300. G_loss 9.102849960327148. D_loss 0.10484933108091354\n",
      "Iteration 6400. G_loss 4.3326029777526855. D_loss 0.04824090003967285\n",
      "Iteration 6500. G_loss 5.32453727722168. D_loss 0.024227267131209373\n",
      "Iteration 6600. G_loss 6.141224384307861. D_loss 0.007599901407957077\n",
      "Iteration 6700. G_loss 13.795912742614746. D_loss 0.09011617302894592\n",
      "Iteration 6800. G_loss 4.603975296020508. D_loss 0.036587994545698166\n",
      "Iteration 6900. G_loss 2.936408042907715. D_loss 0.22617357969284058\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe2abd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "#downloading model\n",
    "print(\"Downloading Data Set!\")\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "mnist_images = mnist.train.images\n",
    "mnist_labels = mnist.train.labels\n",
    "print(\"Finished Downloading!\")\n",
    "\n",
    "#define next batch function\n",
    "r=0\n",
    "def next_batch(data,size):\n",
    "    global r\n",
    "    if r*size+size > len(data):\n",
    "        r=0\n",
    "    x_train_batch = data[size*r:r*size+size,:]\n",
    "    r = r+1\n",
    "    return x_train_batch\n",
    "\n",
    "#definen init weights\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev=0.1))\n",
    "\n",
    "\n",
    "#define bias init\n",
    "def init_bias(shape):\n",
    "    return tf.Variable(tf.constant(0.2,shape=shape))\n",
    "\n",
    "\n",
    "#Define class Generator and its method and init function\n",
    "class Generator:\n",
    "    def __init__(self):\n",
    "        with tf.variable_scope('g'):\n",
    "            self.gW1 = init_weights([100,256])\n",
    "            self.gb1 = init_bias([256])\n",
    "            self.gW2 = init_weights([256,784])\n",
    "            self.gb2 = init_bias([784])\n",
    "            \n",
    "    def forward(self,z,training=True):\n",
    "        fc1 = tf.matmul(z,self.gW1) + self.gb1\n",
    "        fc1 = tf.layers.batch_normalization(fc1,training=training)\n",
    "        fc1 = tf.nn.leaky_relu(fc1)\n",
    "        fc2 = tf.nn.sigmoid(tf.matmul(fc1,self.gW2) + self.gb2)\n",
    "        \n",
    "        return fc2\n",
    "    \n",
    "#Define class Diccriminator and its method and init function\n",
    "class Discriminator:\n",
    "    def __init__(self):\n",
    "        with tf.variable_scope('d'):\n",
    "            self.dW1 = init_weights([5,5,1,16])\n",
    "            self.db1 = init_bias([16])\n",
    "            self.dW2 = init_weights([3,3,16,32])\n",
    "            self.db2 = init_bias([32])\n",
    "            \n",
    "            self.W3 = init_weights([1568,128])\n",
    "            self.b3 = init_bias([128])\n",
    "            self.W4 = init_weights([128,1])\n",
    "            self.b4 = init_bias([1])\n",
    "            \n",
    "    def forward(self,X):\n",
    "        self.X = tf.reshape(X, shape=[-1,28,28,1])\n",
    "        conv1 = tf.nn.leaky_relu(tf.nn.conv2d(self.X, self.dW1, strides=[1,2,2,1], padding='SAME') + self.db1)\n",
    "        conv1 = tf.layers.batch_normalization(conv1,True)\n",
    "        conv2 = tf.nn.leaky_relu(tf.nn.conv2d(conv1,self.dW2, strides=[1,2,2,1],padding='SAME')+self.db2)\n",
    "        conv2 = tf.layers.batch_normalization(conv2,True)\n",
    "        conv2 = tf.reshape(conv2,shape=[-1,7*7*32])\n",
    "        \n",
    "        fc1 = tf.nn.leaky_relu(tf.matmul(conv2,self.W3)  + self.b3)\n",
    "        logits = tf.matmul(fc1,self.W4) + self.b4\n",
    "        fc2 = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return fc2,logits\n",
    "    \n",
    "def cost(logits, labels):\n",
    "    retu n tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "\n",
    "d = Discriminator()\n",
    "g = Generator()\n",
    "\n",
    "phX = tf.placeholder(tf.float32, [None,784])\n",
    "phZ = tf.placeholder(tf.float32, [None, 100])\n",
    "\n",
    "G_out = g.forward(phZ)\n",
    "G_out_sample = g.forward(phZ,False)\n",
    "\n",
    "D_out_real, D_logits_real = d.forward(phX)\n",
    "D_out_fake, D_logits_fake = d.forward(G_out)\n",
    "\n",
    "D_real_loss = cost(D_logits_real, tf.ones_like(D_logits_real))\n",
    "D_fake_loss = cost(D_logits_fake, tf.zeros_like(D_logits_fake))\n",
    "\n",
    "D_loss = D_real_loss + D_fake_loss\n",
    "G_loss = cost(D_logits_fake , tf.ones_like(D_logits_fake))\n",
    "\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "epochs = 7000\n",
    "\n",
    "pretrain_epochs = 4000\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "dvars = [var for var in train_vars if 'd' in var.name]\n",
    "gvars = [var for var in train_vars if 'g' in var.name]\n",
    "\n",
    "D_train = tf.train.AdamOptimizer(lr).minimize(D_loss, var_list = dvars)\n",
    "G_train = tf.train.AdamOptimizer(lr).minimize(G_loss, var_list = gvars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "if not os.path.exists('generated_images/'):\n",
    "    os.makedirs('generated_images/')\n",
    "    \n",
    "# start \n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        sess.run(init)\n",
    "        \n",
    "        k = 0\n",
    "        l = 10\n",
    "        data = mnist_images[mnist_labels == i]\n",
    "        \n",
    "        print(f\"starting training for label {i}\")\n",
    "        \n",
    "        g_cost = []\n",
    "        d_cost = []\n",
    "        \n",
    "        for j in range(epochs):\n",
    "            \n",
    "            batch_X = next_batch(data, batch_size)\n",
    "            \n",
    "            batch_z = np.random.randn(batch_size,100)\n",
    "\n",
    "\n",
    "            _,d_loss = sess.run([D_train,D_loss], feed_dict = {phX:batch_X, phZ:batch_z})\n",
    "            _,g_loss = sess.run([G_train,G_loss], feed_dict = {phZ:batch_z})\n",
    "            \n",
    "            d_cost.append(d_loss)\n",
    "            g_cost.append(g_loss)\n",
    "            \n",
    "            if j % pretrain_epochs//10 == 0 and j<pretrain_epochs:\n",
    "                print(f\"Pretraining. Generating images for label {i}\")\n",
    "                l = l-1\n",
    "                \n",
    "            if j % 100 == 0 and j>=pretrain_epochs:\n",
    "                sample_z = np.random.randn(1,100)\n",
    "                \n",
    "                gen_sample = sess.run(G_out_sample,feed_dict = {phZ:sample_z})\n",
    "                \n",
    "                print(f\"Iteration {j}. G_loss {g_loss}. D_loss {d_loss}\")\n",
    "                \n",
    "                #save\n",
    "                image = plt.imshow(gen_sample.reshape(28,28),cmap=\"Greys_r\")\n",
    "                plt.savefig(f\"generated_images/Sample{i}_{k+1}.png\")\n",
    "                k += 1\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
